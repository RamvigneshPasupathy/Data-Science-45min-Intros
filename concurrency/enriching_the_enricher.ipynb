{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We're going to improve the `tweet_enricher.py` script from [Gnip-Analysis-Pipeline](https://github.com/tw-ddis/Gnip-Analysis-Pipeline). We'll make a simplified version and create variations that improve it in various ways. \n",
    "\n",
    "To enrich tweets, we will need:\n",
    "* a tweet source\n",
    "* a version of the enricher script (we'll use a function)\n",
    "* one or more enrichment classes\n",
    "\n",
    "See the [README](https://github.com/tw-ddis/Gnip-Analysis-Pipeline/blob/master/README.md) for an explanation of these components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A stream of tweets\n",
    "\n",
    "The enrichment step of the analysis pipeline is designed to work on a potentially infinite stream of tweets. A generator will simulate this nicely. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DT_FORMAT_STR = \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "\n",
    "def stream_of_tweets(n=10):\n",
    "    # generator function to generate sequential tweets\n",
    "    for i in range(n):\n",
    "        time.sleep(0.01)\n",
    "        tweet = {\n",
    "            'body':'I am tweet #' + str(i),\n",
    "            'postedTime':datetime.datetime.now().strftime(DT_FORMAT_STR)       \n",
    "                }\n",
    "        yield json.dumps(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in stream_of_tweets(2):\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in stream_of_tweets():\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The tweet enricher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enrich_tweets_1(istream,enrichment_class_list):\n",
    "    \n",
    "    \"\"\" simplified copy of tweet_enricher.py \"\"\"\n",
    "    \n",
    "    enrichment_instance_list = [enrichment_class() for enrichment_class in enrichment_class_list]\n",
    "    \n",
    "    for tweet_str in istream:\n",
    "        try:\n",
    "            tweet = json.loads(tweet_str)\n",
    "        except ValueError:\n",
    "            continue\n",
    "            \n",
    "        for instance in enrichment_instance_list:\n",
    "            instance.enrich(tweet)\n",
    "            \n",
    "        sys.stdout.write( json.dumps(tweet) + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichment classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestEnrichment():\n",
    "    value = 42\n",
    "    def enrich(self,tweet):\n",
    "        if 'enrichments' not in tweet:\n",
    "            tweet['enrichments'] = {}\n",
    "        tweet['enrichments']['TestEnrichment'] = self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestEnrichment2():\n",
    "    value = 48\n",
    "    def enrich(self,tweet):\n",
    "        if 'enrichments' not in tweet:\n",
    "            tweet['enrichments'] = {}\n",
    "        tweet['enrichments']['TestEnrichment2'] = self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_tweets_1(stream_of_tweets(5),[TestEnrichment,TestEnrichment2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convenience and simplification\n",
    "\n",
    "* remove JSON-(de)serialization\n",
    "* use only one enrichment class, derived from a base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DT_FORMAT_STR = \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "\n",
    "def stream_of_tweets(n=10):\n",
    "    # generator function to generate sequential tweets\n",
    "    for i in range(n):\n",
    "        time.sleep(0.01)\n",
    "        tweet = {\n",
    "            'body':'I am tweet #' + str(i),\n",
    "            'postedTime':datetime.datetime.now().strftime(DT_FORMAT_STR)       \n",
    "                }\n",
    "        yield tweet # <<-- this is the only change from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EnrichmentBase():\n",
    "    def enrich(self,tweet):\n",
    "        if 'enrichments' not in tweet:\n",
    "            tweet['enrichments'] = {}\n",
    "        tweet['enrichments'][type(self).__name__] = self.enrichment_value(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestEnrichment(EnrichmentBase):\n",
    "    def enrichment_value(self,tweet):\n",
    "        return 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_tweets_2(istream,enrichment_class,**kwargs):    \n",
    "    \"\"\" \n",
    "    simplify `enrich_tweets_1 :\n",
    "        only one enrichment\n",
    "        generator function\n",
    "        leave tweets as dict objects\n",
    "    \"\"\"\n",
    "    \n",
    "    enrichment_instance = enrichment_class()\n",
    "    \n",
    "    for tweet in istream:\n",
    "        enrichment_instance.enrich(tweet)\n",
    "        sys.stdout.write( str(tweet) + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "enrich_tweets_2(\n",
    "    istream=stream_of_tweets(5),\n",
    "    enrichment_class=TestEnrichment\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SlowEnrichment(EnrichmentBase):\n",
    "    def enrichment_value(self,tweet):\n",
    "        # get the tweet number from body\n",
    "        # and sleep accordingly\n",
    "        seconds = int(tweet['body'][-1]) + 1\n",
    "        time.sleep(seconds)\n",
    "        return str(seconds) + ' second nap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "enrich_tweets_2(\n",
    "    istream=stream_of_tweets(5),\n",
    "    enrichment_class=SlowEnrichment\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## commentary\n",
    "* tweets are run sequentially\n",
    "* tweet dictionary is mutated by `enrich`\n",
    "* yield enriched tweet when ready\n",
    "\n",
    "## problems\n",
    "* there's no reason for subsequent enrichment operations to be blocked by a `sleep` call (imagine the `sleep` is a web request)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threads\n",
    "\n",
    "Despite what you make have heard about Python's Global Interpreter Lock (GIL), core library (read: those written in C) routines can release the GIL while they are waiting on the operating system. The `time.sleep` function is a good example of this, but extends to things like the `requests` package.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "def enrich_tweets_3(istream,enrichment_class):\n",
    "    \"\"\" \n",
    "    use threads to run `enrich`\n",
    "    \"\"\"\n",
    "    enrichment_instance = enrichment_class()\n",
    "    \n",
    "    # we need to hang onto the threads spawned\n",
    "    threads = []\n",
    "    # ...and the tweets\n",
    "    enriched_tweets = []\n",
    "    for tweet in istream:\n",
    "        \n",
    "        # run `enrich` in a new thread\n",
    "        thread = threading.Thread(\n",
    "            target=enrichment_instance.enrich,\n",
    "            args=(tweet,)\n",
    "        )\n",
    "        thread.start() # runs the function in a new thread\n",
    "        threads.append(thread)\n",
    "        \n",
    "        enriched_tweets.append(tweet)\n",
    "        \n",
    "    sys.stderr.write('submitted all tweets to threads' + '\\n')\n",
    "    for thread in threads:\n",
    "        thread.join() # blocks until thread finishes\n",
    "\n",
    "    sys.stderr.write('all threads finished' + '\\n')\n",
    "    for enriched_tweet in enriched_tweets:\n",
    "        sys.stdout.write( str(enriched_tweet) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "enrich_tweets_3(\n",
    "    istream=stream_of_tweets(5),\n",
    "    enrichment_class=SlowEnrichment\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## commentary\n",
    "* run each `enrich` call in a separate thread\n",
    "* memory is shared between threads\n",
    "* execution takes roughly as long as the slowest enrichment\n",
    "\n",
    "## problems\n",
    "* we had to maintain lists of threads and enriched tweets\n",
    "    * no limitation on number of threads\n",
    "    * store all enriched tweets in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_tweets_4(istream,enrichment_class,**kwargs):\n",
    "    \"\"\" \n",
    "    better use of threads\n",
    "    \"\"\"\n",
    "    \n",
    "    enrichment_instance = enrichment_class()\n",
    "    \n",
    "    queue = [] # queue of (thread,tweet) tuples\n",
    "    max_threads = kwargs['max_threads']\n",
    "\n",
    "    for tweet in istream:\n",
    "        \n",
    "        # run `enrich` in a new thread\n",
    "        thread = threading.Thread(\n",
    "            target=enrichment_instance.enrich,\n",
    "            args=(tweet,)\n",
    "        )\n",
    "        thread.start()\n",
    "        queue.append((thread,tweet))\n",
    "\n",
    "        # don't accept more tweets until a thread is free\n",
    "        while len(queue) >= max_threads:\n",
    "            # iterate through all threads\n",
    "            # when threads are dead, remove from queue and yield tweet\n",
    "            new_queue = []\n",
    "            for thread,tweet in queue:\n",
    "                if thread.is_alive():\n",
    "                    new_queue.append((thread,tweet))\n",
    "                else:\n",
    "                    sys.stdout.write( str(tweet) + '\\n') # print enriched tweet\n",
    "            queue = new_queue\n",
    "            time.sleep(0.1)\n",
    "                     \n",
    "    sys.stderr.write('submitted all tweets to threads' + '\\n')\n",
    "    \n",
    "    # cleanup threads that didn't finish while iterating through tweets\n",
    "    for thread,tweet in queue:\n",
    "        thread.join()\n",
    "        time.sleep(0.01)\n",
    "        sys.stdout.write( str(tweet) + '\\n')\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "enrich_tweets_4(\n",
    "    istream=stream_of_tweets(5),\n",
    "    enrichment_class=SlowEnrichment,\n",
    "    max_threads = 7 # play with this number\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## commentary\n",
    "* we limited the number of alive threads\n",
    "* we store no more than `max_threads` tweets in memory\n",
    "\n",
    "## problems\n",
    "* awkward queue length management\n",
    "* have to manage individual threads\n",
    "\n",
    "# Futures\n",
    "\n",
    "A Future is an object that represents a deferred computation that may or may not have completed. That computation might be run on a separate thread but the Future itself doesn't care where the operation is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "def enrich_tweets_5(istream,enrichment_class,**kwargs):\n",
    "    \"\"\" \n",
    "    use concurrent.futures instead of bare Threads\n",
    "    \"\"\"\n",
    "    enrichment_instance = enrichment_class()\n",
    "    \n",
    "    with futures.ThreadPoolExecutor(max_workers=kwargs['max_workers']) as executor:\n",
    "        \n",
    "        future_to_tweet = {}\n",
    "        for tweet in istream:\n",
    "\n",
    "            # run `enrich` in a new thread, via a Future\n",
    "            future = executor.submit(\n",
    "                enrichment_instance.enrich,\n",
    "                tweet\n",
    "            )\n",
    "            future_to_tweet[future] = tweet\n",
    "            \n",
    "        sys.stderr.write('submitted all tweets as futures' + '\\n')    \n",
    "        \n",
    "        for future in futures.as_completed(future_to_tweet):\n",
    "            sys.stdout.write( str(future_to_tweet[future]) + '\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "enrich_tweets_5(\n",
    "    istream=stream_of_tweets(5),\n",
    "    enrichment_class=SlowEnrichment,\n",
    "    max_workers = 5\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## commentary\n",
    "* `futures.as_completed` yields results as execution finishes\n",
    "    * this is better than sequentially `join`-ing threads, as above, because results are yielded as soon as they become available\n",
    "\n",
    "## problems\n",
    "* we haven't limited the number of concurrent workers\n",
    "* we can't yield any results until we've finished looping through the tweet\n",
    "* we have to maintain a dict of _all_ tweets and futures\n",
    "\n",
    "\n",
    "# Change the enrichment protocol\n",
    "\n",
    "Currently, classes follow the enrichment protocol by defining an `enrich` method with the appropriate signature. Nothing is specififed regarding the return type or value.\n",
    "\n",
    "We will now change this protocol such that the `enrich` method _returns_ the enriched tweet dictionary, rather than relying on the mutability of the tweet dictionary passed to `enrich`. This allows us:\n",
    "* to \"store\" tweets in the Future and retrieve the enriched versions, obviating the need to maintain a record of all observed tweets\n",
    "* to generalize the submission interface such that we don't rely on the assumption of shared memory between the threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NewEnrichmentBase():\n",
    "    def enrich(self,tweet):\n",
    "        if 'enrichments' not in tweet:\n",
    "            tweet['enrichments'] = {}\n",
    "        tweet['enrichments'][type(self).__name__] = self.enrichment_value(tweet)\n",
    "        return tweet # <<-- the only new piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NewSlowEnrichment(NewEnrichmentBase):\n",
    "    def enrichment_value(self,tweet):\n",
    "        # get the tweet number from body\n",
    "        # and sleep accordingly\n",
    "        seconds = int(tweet['body'].split('#')[-1]) + 1\n",
    "        if seconds > 9:\n",
    "            seconds = 1\n",
    "        time.sleep(seconds)\n",
    "        return str(seconds) + ' second nap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "def enrich_tweets_6(istream,enrichment_class,**kwargs):\n",
    "    \"\"\" \n",
    "    new enrichment protocol\n",
    "    \"\"\"\n",
    "    \n",
    "    enrichment_instance = enrichment_class()\n",
    "    \n",
    "    with futures.ThreadPoolExecutor(max_workers=kwargs['max_workers']) as executor:\n",
    "        \n",
    "        futures_list = [] # <<-- this is now just a list of futures\n",
    "        for tweet in istream:\n",
    "\n",
    "            # run `enrich` in a new thread, via a Future\n",
    "            future = executor.submit(\n",
    "                enrichment_instance.enrich,\n",
    "                tweet\n",
    "            )\n",
    "            futures_list.append(future)\n",
    "\n",
    "        sys.stderr.write('submitted all tweets as futures' + '\\n')    \n",
    "        \n",
    "        for future in futures.as_completed(futures_list):\n",
    "            sys.stdout.write( str(future.result()) + '\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "enrich_tweets_6(\n",
    "    istream=stream_of_tweets(5),\n",
    "    enrichment_class=NewSlowEnrichment,\n",
    "    max_workers = 5\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## commentary\n",
    "* as before, results are yielded as soon as they are ready\n",
    "* we keep no explicit record of all tweets\n",
    "\n",
    "## problems\n",
    "* we don't get any results until we've iterated through all tweets, so we still keep an implicit list of all tweets\n",
    "* we have no limitation on the number of concurrent Future objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "def enrich_tweets_7(istream,enrichment_class,**kwargs):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "\n",
    "    def print_the_tweet(future):\n",
    "        #return future.result()\n",
    "        sys.stdout.write( str(future.result()) + '\\n') \n",
    "    \n",
    "    enrichment_instance = enrichment_class()\n",
    "    \n",
    "    with futures.ThreadPoolExecutor(max_workers=kwargs['max_workers']) as executor:\n",
    "        \n",
    "        for tweet in istream:\n",
    "\n",
    "            # run `enrich` in a new thread, via a Future\n",
    "            future = executor.submit(\n",
    "                enrichment_instance.enrich,\n",
    "                tweet\n",
    "            )\n",
    "            future.add_done_callback(print_the_tweet)\n",
    "            \n",
    "        sys.stderr.write('submitted all tweets as futures' + '\\n')    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "enrich_tweets_7(\n",
    "    istream=stream_of_tweets(5),\n",
    "    enrichment_class=NewSlowEnrichment,\n",
    "    max_workers = 2\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## commentary\n",
    "* no explicit list of futures\n",
    "* callback function is run in the main thread\n",
    "* putting the print statement in the callback function allows the output to run asynchronously\n",
    "\n",
    "## problems\n",
    "* we haven't limited the number of queued operations in the executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "def enrich_tweets_8(istream,enrichment_class,**kwargs):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    max_workers = kwargs['max_workers']\n",
    "    \n",
    "    def print_the_tweet(future):\n",
    "        sys.stdout.write( str(future.result()) + '\\n') \n",
    "    \n",
    "    enrichment_instance = enrichment_class()\n",
    "    \n",
    "    with futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        \n",
    "        futures_list = []\n",
    "        for tweet in istream:\n",
    "\n",
    "            # run `enrich` in a new thread, via a Future\n",
    "            future = executor.submit(\n",
    "                enrichment_instance.enrich,\n",
    "                tweet\n",
    "            )\n",
    "            future.add_done_callback(print_the_tweet)\n",
    "            futures_list.append(future)\n",
    "        \n",
    "            futures_list[:] = [future for future in futures_list if future.running()]\n",
    "            while len(futures_list) >= max_workers:\n",
    "                futures_list[:] = [future for future in futures_list if future.running()]\n",
    "                time.sleep(0.5)\n",
    "\n",
    "\n",
    "        sys.stderr.write('submitted all tweets as futures' + '\\n')    \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "enrich_tweets_8(\n",
    "    istream=stream_of_tweets(50),\n",
    "    enrichment_class=NewSlowEnrichment,\n",
    "    max_workers = 50\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## commentary\n",
    "* we can now safely stream tweets into the enrich function, without queueing every tweet in the executor\n",
    "\n",
    "## problems\n",
    "* the buffering of calls to `submit` is still a bit of a hack, and potentially slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import queue\n",
    "def enrich_tweets_9(istream,enrichment_class,**kwargs):\n",
    "    \"\"\" \n",
    "    use a pool of threads, each running a worker reading from a common queue\n",
    "    \"\"\"\n",
    "    \n",
    "    max_workers = kwargs['max_workers']\n",
    "    queue_size = kwargs['queue_size']\n",
    "    \n",
    "    enrichment_instance = enrichment_class()\n",
    "        \n",
    "    def worker():\n",
    "        \"\"\"\n",
    "        this function runs on new threads\n",
    "        and reads from a common queue\n",
    "        \"\"\"\n",
    "        time.sleep(0.5)\n",
    "        while True:\n",
    "            tweet = q.get()\n",
    "            if tweet is None: # this is the signal to exit\n",
    "                break\n",
    "            enrichment_instance.enrich(tweet)\n",
    "            sys.stdout.write(str(tweet) + '\\n')\n",
    "            q.task_done()\n",
    "            time.sleep(0.1)\n",
    "          \n",
    "    thread_pool = [threading.Thread(target=worker) for _ in range(max_workers)]\n",
    "    [thread.start() for thread in thread_pool]\n",
    "    \n",
    "    q = queue.Queue(maxsize=queue_size)\n",
    "                             \n",
    "    for tweet in istream:\n",
    "\n",
    "        q.put(tweet)\n",
    "    \n",
    "    sys.stderr.write('submitted all tweets to threads' + '\\n')    \n",
    "  \n",
    "    # block until queue is empty\n",
    "    q.join()\n",
    "\n",
    "    # kill the threads\n",
    "    for _ in range(len(thread_pool)):\n",
    "        q.put(None)    \n",
    "    for thread in thread_pool:\n",
    "        thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "enrich_tweets_9(\n",
    "    istream=stream_of_tweets(5),\n",
    "    enrichment_class=NewSlowEnrichment,\n",
    "    max_workers = 10,\n",
    "    queue_size=5\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## commentary\n",
    "* tweets are proccessed and returned fully asynchronously on a fixed pool of threads\n",
    "* the queue throttles the incoming tweet stream\n",
    "\n",
    "## problems\n",
    "* what about CPU-bound tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "import hashlib\n",
    "\n",
    "class CPUBoundEnrichment(NewEnrichmentBase):\n",
    "    def enrichment_value(self,tweet):\n",
    "        # make a SHA-256 hash of random byte arrays\n",
    "        data = bytearray(randrange(256) for i in range(2**21)) \n",
    "        algo = hashlib.new('sha256')\n",
    "        algo.update(data)\n",
    "        return algo.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enrich_tweets_10(istream,enrichment_class,**kwargs):\n",
    "    \"\"\" \n",
    "    use a `ProcessPoolExecutor` to manage processes\n",
    "    \"\"\"\n",
    "    \n",
    "    max_workers=kwargs['max_workers']\n",
    "    executor_name=kwargs['executor_name']\n",
    "    \n",
    "    def print_the_tweet(future):\n",
    "        sys.stdout.write( str(future.result()) + '\\n') \n",
    "    \n",
    "    enrichment_instance = enrichment_class()\n",
    "    \n",
    "    with getattr(futures,executor_name)(max_workers=max_workers) as executor: # <- this is the only change from #8\n",
    "        \n",
    "        futures_list = []\n",
    "        for tweet in istream:\n",
    "\n",
    "            # run `enrich` in a new thread, via a Future\n",
    "            future = executor.submit(\n",
    "                enrichment_instance.enrich,\n",
    "                tweet\n",
    "            )\n",
    "            future.add_done_callback(print_the_tweet)\n",
    "            futures_list.append(future)\n",
    "        \n",
    "            # have to throttle with this hack\n",
    "            futures_list[:] = [future for future in futures_list if future.running()]\n",
    "            while len(futures_list) >= max_workers:\n",
    "                futures_list[:] = [future for future in futures_list if future.running()]\n",
    "                time.sleep(0.5)\n",
    "\n",
    "        sys.stderr.write('submitted all tweets as futures' + '\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "enrich_tweets_10(\n",
    "    istream=stream_of_tweets(5),\n",
    "    enrichment_class=CPUBoundEnrichment,\n",
    "    executor_name='ProcessPoolExecutor',\n",
    "    max_workers = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exercises for the reader\n",
    "* use a pool of `Process` objects, a `multiprocess.Queue`, and a callback function to build a single-queue example with processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
